# 1 数据预处理
## 1.1 pcap的处理
如何将pcap转为csv？
- 使用工具CICFlowMeter
## 1.2 csv的数据预处理
1. __csv的数据合并：__ 一个类别下面不止一个pcap，故生成了多个csv文件，需要读取到内存然后合并，作为最终的类别
2. __重复值与缺失值处理：__ 去重，缺失值NaN的行去掉，有无穷inf值的行去掉
# 2 特征工程
84维的特征不能全部塞进分类器，要进行特征工程，选择出重要的特征送入分类器就可以了，这里使用随机森林的特征选择方法来评估特征的重要性程度。具体而言，可以利用训练好的随机森林模型，在训练过程中统计各个特征的重要性得分，并根据得分对特征进行排序，以此评估每个特征对模型的影响力大小。
1. 特征编码：把NoVPN编码为0，VPN编码为1
2. 缺失值的列除去：除去了`'Flow Byts/s'`,`'Flow Pkts/s'`这两列
3. 特征归一化：使用了最大最小归一化，将特征区间缩放到[0,1]
4. 基于随机森林特征选择方法对特征重要度进行评分,选择出重要度排名前列的特征
# 3 决策分类
1. 数据分割：数据划分为训练集与测试集8:2
2. 过采样：对训练集进行过采样
> 数据不平衡问题在机器学习中很常见，其中一种处理方法是过采样（oversampling）。过采样的基本思路是通过增加少数类样本的数量来获得更多的有效信息，从而提高模型对少数类样本的识别能力。 一种简单的过采样方法是 SMOTE(Synthetic Minority Over-sampling Technique)，即合成少数类过采样技术。SMOTE 随机选择一个少数类样本，然后随机选择若干个最近邻数据点，在该样本和这些最近邻点之间进行插值，生成新的少数类样本。过采样操作应该在划分训练集和测试集之前进行，否则会将相同的数据出现在训练集和测试集中，从而导致模型泛化性能下降的问题。因此，建议先将数据集划分为训练集和测试集，再对训练集进行过采样处理。
3. 使用GDBT、SVM、LR三种模型进行训练对比


> 因文件大小限制，csv一些文件不全
